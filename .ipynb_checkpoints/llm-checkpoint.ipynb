{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7fd72bdd",
   "metadata": {},
   "source": [
    "# setting up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1bccd034",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'tensorflow'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Input \u001b[0;32mIn [4]\u001b[0m, in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mnumpy\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mnp\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mpd\u001b[39;00m\n\u001b[0;32m----> 3\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mtf\u001b[39;00m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mlayers\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Dense, Input\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01moptimizers\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Adam\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'tensorflow'"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import Dense, Input\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint\n",
    "import tensorflow_hub as hub\n",
    "import re\n",
    "from sklearn.model_selection import train_test_split\n",
    "from bert import tokenization"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "037affb4",
   "metadata": {},
   "source": [
    "# Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f5b2772e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>location</th>\n",
       "      <th>department</th>\n",
       "      <th>salary_range</th>\n",
       "      <th>company_profile</th>\n",
       "      <th>description</th>\n",
       "      <th>requirements</th>\n",
       "      <th>benefits</th>\n",
       "      <th>telecommuting</th>\n",
       "      <th>has_company_logo</th>\n",
       "      <th>has_questions</th>\n",
       "      <th>employment_type</th>\n",
       "      <th>required_experience</th>\n",
       "      <th>required_education</th>\n",
       "      <th>industry</th>\n",
       "      <th>function</th>\n",
       "      <th>fraudulent</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Marketing Intern</td>\n",
       "      <td>US, NY, New York</td>\n",
       "      <td>Marketing</td>\n",
       "      <td>NaN</td>\n",
       "      <td>We're Food52, and we've created a groundbreaki...</td>\n",
       "      <td>Food52, a fast-growing, James Beard Award-winn...</td>\n",
       "      <td>Experience with content management systems a m...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>Other</td>\n",
       "      <td>Internship</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Marketing</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Customer Service - Cloud Video Production</td>\n",
       "      <td>NZ, , Auckland</td>\n",
       "      <td>Success</td>\n",
       "      <td>NaN</td>\n",
       "      <td>90 Seconds, the worlds Cloud Video Production ...</td>\n",
       "      <td>Organised - Focused - Vibrant - Awesome!Do you...</td>\n",
       "      <td>What we expect from you:Your key responsibilit...</td>\n",
       "      <td>What you will get from usThrough being part of...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>Full-time</td>\n",
       "      <td>Not Applicable</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Marketing and Advertising</td>\n",
       "      <td>Customer Service</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Commissioning Machinery Assistant (CMA)</td>\n",
       "      <td>US, IA, Wever</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Valor Services provides Workforce Solutions th...</td>\n",
       "      <td>Our client, located in Houston, is actively se...</td>\n",
       "      <td>Implement pre-commissioning and commissioning ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Account Executive - Washington DC</td>\n",
       "      <td>US, DC, Washington</td>\n",
       "      <td>Sales</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Our passion for improving quality of life thro...</td>\n",
       "      <td>THE COMPANY: ESRI – Environmental Systems Rese...</td>\n",
       "      <td>EDUCATION: Bachelor’s or Master’s in GIS, busi...</td>\n",
       "      <td>Our culture is anything but corporate—we have ...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>Full-time</td>\n",
       "      <td>Mid-Senior level</td>\n",
       "      <td>Bachelor's Degree</td>\n",
       "      <td>Computer Software</td>\n",
       "      <td>Sales</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Bill Review Manager</td>\n",
       "      <td>US, FL, Fort Worth</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>SpotSource Solutions LLC is a Global Human Cap...</td>\n",
       "      <td>JOB TITLE: Itemization Review ManagerLOCATION:...</td>\n",
       "      <td>QUALIFICATIONS:RN license in the State of Texa...</td>\n",
       "      <td>Full Benefits Offered</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Full-time</td>\n",
       "      <td>Mid-Senior level</td>\n",
       "      <td>Bachelor's Degree</td>\n",
       "      <td>Hospital &amp; Health Care</td>\n",
       "      <td>Health Care Provider</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17875</th>\n",
       "      <td>Account Director - Distribution</td>\n",
       "      <td>CA, ON, Toronto</td>\n",
       "      <td>Sales</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Vend is looking for some awesome new talent to...</td>\n",
       "      <td>Just in case this is the first time you’ve vis...</td>\n",
       "      <td>To ace this role you:Will eat comprehensive St...</td>\n",
       "      <td>What can you expect from us?We have an open cu...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Full-time</td>\n",
       "      <td>Mid-Senior level</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Computer Software</td>\n",
       "      <td>Sales</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17876</th>\n",
       "      <td>Payroll Accountant</td>\n",
       "      <td>US, PA, Philadelphia</td>\n",
       "      <td>Accounting</td>\n",
       "      <td>NaN</td>\n",
       "      <td>WebLinc is the e-commerce platform and service...</td>\n",
       "      <td>The Payroll Accountant will focus primarily on...</td>\n",
       "      <td>- B.A. or B.S. in Accounting- Desire to have f...</td>\n",
       "      <td>Health &amp;amp; WellnessMedical planPrescription ...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Full-time</td>\n",
       "      <td>Mid-Senior level</td>\n",
       "      <td>Bachelor's Degree</td>\n",
       "      <td>Internet</td>\n",
       "      <td>Accounting/Auditing</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17877</th>\n",
       "      <td>Project Cost Control Staff Engineer - Cost Con...</td>\n",
       "      <td>US, TX, Houston</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>We Provide Full Time Permanent Positions for m...</td>\n",
       "      <td>Experienced Project Cost Control Staff Enginee...</td>\n",
       "      <td>At least 12 years professional experience.Abil...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Full-time</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17878</th>\n",
       "      <td>Graphic Designer</td>\n",
       "      <td>NG, LA, Lagos</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Nemsia Studios is looking for an experienced v...</td>\n",
       "      <td>1. Must be fluent in the latest versions of Co...</td>\n",
       "      <td>Competitive salary (compensation will be based...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>Contract</td>\n",
       "      <td>Not Applicable</td>\n",
       "      <td>Professional</td>\n",
       "      <td>Graphic Design</td>\n",
       "      <td>Design</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17879</th>\n",
       "      <td>Web Application Developers</td>\n",
       "      <td>NZ, N, Wellington</td>\n",
       "      <td>Engineering</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Vend is looking for some awesome new talent to...</td>\n",
       "      <td>Who are we?Vend is an award winning web based ...</td>\n",
       "      <td>We want to hear from you if:You have an in-dep...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Full-time</td>\n",
       "      <td>Mid-Senior level</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Computer Software</td>\n",
       "      <td>Engineering</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>17880 rows × 17 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   title  \\\n",
       "0                                       Marketing Intern   \n",
       "1              Customer Service - Cloud Video Production   \n",
       "2                Commissioning Machinery Assistant (CMA)   \n",
       "3                      Account Executive - Washington DC   \n",
       "4                                    Bill Review Manager   \n",
       "...                                                  ...   \n",
       "17875                   Account Director - Distribution    \n",
       "17876                                 Payroll Accountant   \n",
       "17877  Project Cost Control Staff Engineer - Cost Con...   \n",
       "17878                                   Graphic Designer   \n",
       "17879                         Web Application Developers   \n",
       "\n",
       "                   location   department salary_range  \\\n",
       "0          US, NY, New York    Marketing          NaN   \n",
       "1            NZ, , Auckland      Success          NaN   \n",
       "2             US, IA, Wever          NaN          NaN   \n",
       "3        US, DC, Washington        Sales          NaN   \n",
       "4        US, FL, Fort Worth          NaN          NaN   \n",
       "...                     ...          ...          ...   \n",
       "17875       CA, ON, Toronto        Sales          NaN   \n",
       "17876  US, PA, Philadelphia   Accounting          NaN   \n",
       "17877       US, TX, Houston          NaN          NaN   \n",
       "17878         NG, LA, Lagos          NaN          NaN   \n",
       "17879     NZ, N, Wellington  Engineering          NaN   \n",
       "\n",
       "                                         company_profile  \\\n",
       "0      We're Food52, and we've created a groundbreaki...   \n",
       "1      90 Seconds, the worlds Cloud Video Production ...   \n",
       "2      Valor Services provides Workforce Solutions th...   \n",
       "3      Our passion for improving quality of life thro...   \n",
       "4      SpotSource Solutions LLC is a Global Human Cap...   \n",
       "...                                                  ...   \n",
       "17875  Vend is looking for some awesome new talent to...   \n",
       "17876  WebLinc is the e-commerce platform and service...   \n",
       "17877  We Provide Full Time Permanent Positions for m...   \n",
       "17878                                                NaN   \n",
       "17879  Vend is looking for some awesome new talent to...   \n",
       "\n",
       "                                             description  \\\n",
       "0      Food52, a fast-growing, James Beard Award-winn...   \n",
       "1      Organised - Focused - Vibrant - Awesome!Do you...   \n",
       "2      Our client, located in Houston, is actively se...   \n",
       "3      THE COMPANY: ESRI – Environmental Systems Rese...   \n",
       "4      JOB TITLE: Itemization Review ManagerLOCATION:...   \n",
       "...                                                  ...   \n",
       "17875  Just in case this is the first time you’ve vis...   \n",
       "17876  The Payroll Accountant will focus primarily on...   \n",
       "17877  Experienced Project Cost Control Staff Enginee...   \n",
       "17878  Nemsia Studios is looking for an experienced v...   \n",
       "17879  Who are we?Vend is an award winning web based ...   \n",
       "\n",
       "                                            requirements  \\\n",
       "0      Experience with content management systems a m...   \n",
       "1      What we expect from you:Your key responsibilit...   \n",
       "2      Implement pre-commissioning and commissioning ...   \n",
       "3      EDUCATION: Bachelor’s or Master’s in GIS, busi...   \n",
       "4      QUALIFICATIONS:RN license in the State of Texa...   \n",
       "...                                                  ...   \n",
       "17875  To ace this role you:Will eat comprehensive St...   \n",
       "17876  - B.A. or B.S. in Accounting- Desire to have f...   \n",
       "17877  At least 12 years professional experience.Abil...   \n",
       "17878  1. Must be fluent in the latest versions of Co...   \n",
       "17879  We want to hear from you if:You have an in-dep...   \n",
       "\n",
       "                                                benefits  telecommuting  \\\n",
       "0                                                    NaN              0   \n",
       "1      What you will get from usThrough being part of...              0   \n",
       "2                                                    NaN              0   \n",
       "3      Our culture is anything but corporate—we have ...              0   \n",
       "4                                  Full Benefits Offered              0   \n",
       "...                                                  ...            ...   \n",
       "17875  What can you expect from us?We have an open cu...              0   \n",
       "17876  Health &amp; WellnessMedical planPrescription ...              0   \n",
       "17877                                                NaN              0   \n",
       "17878  Competitive salary (compensation will be based...              0   \n",
       "17879                                                NaN              0   \n",
       "\n",
       "       has_company_logo  has_questions employment_type required_experience  \\\n",
       "0                     1              0           Other          Internship   \n",
       "1                     1              0       Full-time      Not Applicable   \n",
       "2                     1              0             NaN                 NaN   \n",
       "3                     1              0       Full-time    Mid-Senior level   \n",
       "4                     1              1       Full-time    Mid-Senior level   \n",
       "...                 ...            ...             ...                 ...   \n",
       "17875                 1              1       Full-time    Mid-Senior level   \n",
       "17876                 1              1       Full-time    Mid-Senior level   \n",
       "17877                 0              0       Full-time                 NaN   \n",
       "17878                 0              1        Contract      Not Applicable   \n",
       "17879                 1              1       Full-time    Mid-Senior level   \n",
       "\n",
       "      required_education                   industry              function  \\\n",
       "0                    NaN                        NaN             Marketing   \n",
       "1                    NaN  Marketing and Advertising      Customer Service   \n",
       "2                    NaN                        NaN                   NaN   \n",
       "3      Bachelor's Degree          Computer Software                 Sales   \n",
       "4      Bachelor's Degree     Hospital & Health Care  Health Care Provider   \n",
       "...                  ...                        ...                   ...   \n",
       "17875                NaN          Computer Software                 Sales   \n",
       "17876  Bachelor's Degree                   Internet   Accounting/Auditing   \n",
       "17877                NaN                        NaN                   NaN   \n",
       "17878       Professional             Graphic Design                Design   \n",
       "17879                NaN          Computer Software           Engineering   \n",
       "\n",
       "       fraudulent  \n",
       "0               0  \n",
       "1               0  \n",
       "2               0  \n",
       "3               0  \n",
       "4               0  \n",
       "...           ...  \n",
       "17875           0  \n",
       "17876           0  \n",
       "17877           0  \n",
       "17878           0  \n",
       "17879           0  \n",
       "\n",
       "[17880 rows x 17 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load data\n",
    "df = pd.read_csv('fake_job_postings.csv')\n",
    "# drop job id column\n",
    "df.drop('job_id', axis=1, inplace=True)\n",
    "# view data\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c9da2bcd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "title                      0\n",
       "location                 346\n",
       "department             11547\n",
       "salary_range           15012\n",
       "company_profile         3308\n",
       "description                1\n",
       "requirements            2695\n",
       "benefits                7210\n",
       "telecommuting              0\n",
       "has_company_logo           0\n",
       "has_questions              0\n",
       "employment_type         3471\n",
       "required_experience     7050\n",
       "required_education      8105\n",
       "industry                4903\n",
       "function                6455\n",
       "fraudulent                 0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# missing data\n",
    "df.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c4ee146b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.fillna(' ',inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e406b488",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create text column\n",
    "df['text'] = df['title'] + \" \" + df['company_profile'] + \" \" + df['description'] + \" \" + df['department'] + \" \" + df['requirements'] + \" \" + df['benefits'] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e4f13e9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# data cleaning\n",
    "df['text']=df['text'].str.replace('\\n','')\n",
    "df['text']=df['text'].str.replace('\\r','')\n",
    "df['text']=df['text'].str.replace('\\t','')\n",
    "  \n",
    "  #This removes unwanted texts\n",
    "df['text'] = df['text'].apply(lambda x: re.sub(r'[0-9]','',x))\n",
    "df['text'] = df['text'].apply(lambda x: re.sub(r'[/(){}\\[\\]\\|@,;.:-]',' ',x))\n",
    "  \n",
    "  #Converting all upper case to lower case\n",
    "df['text']= df['text'].apply(lambda s:s.lower() if type(s) == str else s)\n",
    "  \n",
    "\n",
    "  #Remove un necessary white space\n",
    "df['text']=df['text'].str.replace('  ',' ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "697c8acb",
   "metadata": {},
   "outputs": [],
   "source": [
    "X =df['text']\n",
    "Y=df['fraudulent']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5a9309a",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X,Y, test_size = 0.20,random_state=127)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a296a63",
   "metadata": {},
   "source": [
    "# BERT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "521ba8a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def bert_encode(texts, tokenizer, max_len=512):\n",
    "    all_tokens = []\n",
    "    all_masks = []\n",
    "    all_segments = []\n",
    "        \n",
    "    for text in texts:\n",
    "        text = tokenizer.tokenize(text)\n",
    "            \n",
    "        text = text[:max_len-2]\n",
    "        input_sequence = [\"[CLS]\"] + text + [\"[SEP]\"]\n",
    "        pad_len = max_len - len(input_sequence)\n",
    "        \n",
    "        tokens = tokenizer.convert_tokens_to_ids(input_sequence)\n",
    "        tokens += [0] * pad_len\n",
    "        pad_masks = [1] * len(input_sequence) + [0] * pad_len\n",
    "        segment_ids = [0] * max_len\n",
    "        \n",
    "        all_tokens.append(tokens)\n",
    "        all_masks.append(pad_masks)\n",
    "        all_segments.append(segment_ids)\n",
    "    \n",
    "    return np.array(all_tokens), np.array(all_masks), np.array(all_segments)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "41dcbe3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model(bert_layer, max_len=512):\n",
    "    input_word_ids = Input(shape=(max_len,), dtype=tf.int32, name=\"input_word_ids\")\n",
    "    input_mask = Input(shape=(max_len,), dtype=tf.int32, name=\"input_mask\")\n",
    "    input_type_ids = Input(shape=(max_len,), dtype=tf.int32, name=\"input_type_ids\")\n",
    "\n",
    "    _, sequence_output = bert_layer([input_word_ids, input_mask, input_type_ids])\n",
    "    clf_output = sequence_output[:, 0, :]\n",
    "    out = Dense(1, activation='sigmoid')(clf_output)\n",
    "    \n",
    "    model = Model(inputs=[input_word_ids, input_mask, input_type_ids], outputs=out)\n",
    "    model.compile(Adam(lr=2e-6), loss='binary_crossentropy', metrics=['accuracy'])\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "cdddb7f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "module_url = \"https://tfhub.dev/tensorflow/small_bert/bert_en_uncased_L-8_H-512_A-8/2\"\n",
    "bert_layer = hub.KerasLayer(module_url, trainable=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "e8f06489",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded BERT: <tensorflow_hub.keras_layer.KerasLayer object at 0x7fced572b490>\n"
     ]
    }
   ],
   "source": [
    "print(f'Loaded BERT: {bert_layer}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "67805bf6",
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab_file = bert_layer.resolved_object.vocab_file.asset_path.numpy()\n",
    "do_lower_case = bert_layer.resolved_object.do_lower_case.numpy()\n",
    "tokenizer = tokenization.FullTokenizer(vocab_file, do_lower_case)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "97f798bd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['preserve_unused_tokens=False']"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# im not sure what this is but if i don't have it then all the code breaks\n",
    "import sys\n",
    "from absl import flags\n",
    "sys.argv=['preserve_unused_tokens=False']\n",
    "flags.FLAGS(sys.argv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "b362cd4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_input = bert_encode(X_train.values, tokenizer, max_len=160)\n",
    "test_input = bert_encode(X_test.values, tokenizer, max_len=160)\n",
    "train_labels = y_train.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "29b549a3",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Exception encountered when calling layer \"keras_layer_2\" (type KerasLayer).\n\nin user code:\n\n    File \"/opt/anaconda3/lib/python3.8/site-packages/tensorflow_hub/keras_layer.py\", line 237, in call  *\n        result = smart_cond.smart_cond(training,\n\n    ValueError: Could not find matching concrete function to call loaded from the SavedModel. Got:\n      Positional arguments (3 total):\n        * [<tf.Tensor 'inputs:0' shape=(None, 160) dtype=int32>, <tf.Tensor 'inputs_1:0' shape=(None, 160) dtype=int32>, <tf.Tensor 'inputs_2:0' shape=(None, 160) dtype=int32>]\n        * False\n        * None\n      Keyword arguments: {}\n    \n     Expected these arguments to match one of the following 4 option(s):\n    \n    Option 1:\n      Positional arguments (3 total):\n        * {'input_type_ids': TensorSpec(shape=(None, None), dtype=tf.int32, name='input_type_ids'), 'input_mask': TensorSpec(shape=(None, None), dtype=tf.int32, name='input_mask'), 'input_word_ids': TensorSpec(shape=(None, None), dtype=tf.int32, name='input_word_ids')}\n        * False\n        * None\n      Keyword arguments: {}\n    \n    Option 2:\n      Positional arguments (3 total):\n        * {'input_type_ids': TensorSpec(shape=(None, None), dtype=tf.int32, name='inputs/input_type_ids'), 'input_mask': TensorSpec(shape=(None, None), dtype=tf.int32, name='inputs/input_mask'), 'input_word_ids': TensorSpec(shape=(None, None), dtype=tf.int32, name='inputs/input_word_ids')}\n        * False\n        * None\n      Keyword arguments: {}\n    \n    Option 3:\n      Positional arguments (3 total):\n        * {'input_word_ids': TensorSpec(shape=(None, None), dtype=tf.int32, name='inputs/input_word_ids'), 'input_type_ids': TensorSpec(shape=(None, None), dtype=tf.int32, name='inputs/input_type_ids'), 'input_mask': TensorSpec(shape=(None, None), dtype=tf.int32, name='inputs/input_mask')}\n        * True\n        * None\n      Keyword arguments: {}\n    \n    Option 4:\n      Positional arguments (3 total):\n        * {'input_mask': TensorSpec(shape=(None, None), dtype=tf.int32, name='input_mask'), 'input_word_ids': TensorSpec(shape=(None, None), dtype=tf.int32, name='input_word_ids'), 'input_type_ids': TensorSpec(shape=(None, None), dtype=tf.int32, name='input_type_ids')}\n        * True\n        * None\n      Keyword arguments: {}\n\n\nCall arguments received:\n  • inputs=['tf.Tensor(shape=(None, 160), dtype=int32)', 'tf.Tensor(shape=(None, 160), dtype=int32)', 'tf.Tensor(shape=(None, 160), dtype=int32)']\n  • training=False",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Input \u001b[0;32mIn [31]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0m model \u001b[38;5;241m=\u001b[39m \u001b[43mbuild_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbert_layer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_len\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m160\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m      2\u001b[0m model\u001b[38;5;241m.\u001b[39msummary()\n",
      "Input \u001b[0;32mIn [30]\u001b[0m, in \u001b[0;36mbuild_model\u001b[0;34m(bert_layer, max_len)\u001b[0m\n\u001b[1;32m      3\u001b[0m input_mask \u001b[38;5;241m=\u001b[39m Input(shape\u001b[38;5;241m=\u001b[39m(max_len,), dtype\u001b[38;5;241m=\u001b[39mtf\u001b[38;5;241m.\u001b[39mint32, name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124minput_mask\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m      4\u001b[0m input_type_ids \u001b[38;5;241m=\u001b[39m Input(shape\u001b[38;5;241m=\u001b[39m(max_len,), dtype\u001b[38;5;241m=\u001b[39mtf\u001b[38;5;241m.\u001b[39mint32, name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124minput_type_ids\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m----> 6\u001b[0m _, sequence_output \u001b[38;5;241m=\u001b[39m \u001b[43mbert_layer\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[43minput_word_ids\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minput_mask\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minput_type_ids\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      7\u001b[0m clf_output \u001b[38;5;241m=\u001b[39m sequence_output[:, \u001b[38;5;241m0\u001b[39m, :]\n\u001b[1;32m      8\u001b[0m out \u001b[38;5;241m=\u001b[39m Dense(\u001b[38;5;241m1\u001b[39m, activation\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124msigmoid\u001b[39m\u001b[38;5;124m'\u001b[39m)(clf_output)\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.8/site-packages/keras/utils/traceback_utils.py:67\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     65\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:  \u001b[38;5;66;03m# pylint: disable=broad-except\u001b[39;00m\n\u001b[1;32m     66\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[0;32m---> 67\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28mNone\u001b[39m\n\u001b[1;32m     68\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m     69\u001b[0m   \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.8/site-packages/tensorflow/python/autograph/impl/api.py:692\u001b[0m, in \u001b[0;36mconvert.<locals>.decorator.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    690\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:  \u001b[38;5;66;03m# pylint:disable=broad-except\u001b[39;00m\n\u001b[1;32m    691\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(e, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mag_error_metadata\u001b[39m\u001b[38;5;124m'\u001b[39m):\n\u001b[0;32m--> 692\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mag_error_metadata\u001b[38;5;241m.\u001b[39mto_exception(e)\n\u001b[1;32m    693\u001b[0m   \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    694\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m\n",
      "\u001b[0;31mValueError\u001b[0m: Exception encountered when calling layer \"keras_layer_2\" (type KerasLayer).\n\nin user code:\n\n    File \"/opt/anaconda3/lib/python3.8/site-packages/tensorflow_hub/keras_layer.py\", line 237, in call  *\n        result = smart_cond.smart_cond(training,\n\n    ValueError: Could not find matching concrete function to call loaded from the SavedModel. Got:\n      Positional arguments (3 total):\n        * [<tf.Tensor 'inputs:0' shape=(None, 160) dtype=int32>, <tf.Tensor 'inputs_1:0' shape=(None, 160) dtype=int32>, <tf.Tensor 'inputs_2:0' shape=(None, 160) dtype=int32>]\n        * False\n        * None\n      Keyword arguments: {}\n    \n     Expected these arguments to match one of the following 4 option(s):\n    \n    Option 1:\n      Positional arguments (3 total):\n        * {'input_type_ids': TensorSpec(shape=(None, None), dtype=tf.int32, name='input_type_ids'), 'input_mask': TensorSpec(shape=(None, None), dtype=tf.int32, name='input_mask'), 'input_word_ids': TensorSpec(shape=(None, None), dtype=tf.int32, name='input_word_ids')}\n        * False\n        * None\n      Keyword arguments: {}\n    \n    Option 2:\n      Positional arguments (3 total):\n        * {'input_type_ids': TensorSpec(shape=(None, None), dtype=tf.int32, name='inputs/input_type_ids'), 'input_mask': TensorSpec(shape=(None, None), dtype=tf.int32, name='inputs/input_mask'), 'input_word_ids': TensorSpec(shape=(None, None), dtype=tf.int32, name='inputs/input_word_ids')}\n        * False\n        * None\n      Keyword arguments: {}\n    \n    Option 3:\n      Positional arguments (3 total):\n        * {'input_word_ids': TensorSpec(shape=(None, None), dtype=tf.int32, name='inputs/input_word_ids'), 'input_type_ids': TensorSpec(shape=(None, None), dtype=tf.int32, name='inputs/input_type_ids'), 'input_mask': TensorSpec(shape=(None, None), dtype=tf.int32, name='inputs/input_mask')}\n        * True\n        * None\n      Keyword arguments: {}\n    \n    Option 4:\n      Positional arguments (3 total):\n        * {'input_mask': TensorSpec(shape=(None, None), dtype=tf.int32, name='input_mask'), 'input_word_ids': TensorSpec(shape=(None, None), dtype=tf.int32, name='input_word_ids'), 'input_type_ids': TensorSpec(shape=(None, None), dtype=tf.int32, name='input_type_ids')}\n        * True\n        * None\n      Keyword arguments: {}\n\n\nCall arguments received:\n  • inputs=['tf.Tensor(shape=(None, 160), dtype=int32)', 'tf.Tensor(shape=(None, 160), dtype=int32)', 'tf.Tensor(shape=(None, 160), dtype=int32)']\n  • training=False"
     ]
    }
   ],
   "source": [
    "model = build_model(bert_layer, max_len=160)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c205c94a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "6f6f1f23",
   "metadata": {},
   "source": [
    "# TF tutorial\n",
    "https://www.tensorflow.org/text/tutorials/classify_text_with_bert#about_bert"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "902bcbcd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: tensorflow in /Users/ankitasingh/miniconda3/envs/tf/lib/python3.9/site-packages (2.12.0)\n",
      "Requirement already satisfied: keras<2.13,>=2.12.0 in /Users/ankitasingh/miniconda3/envs/tf/lib/python3.9/site-packages (from tensorflow) (2.12.0)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in /Users/ankitasingh/miniconda3/envs/tf/lib/python3.9/site-packages (from tensorflow) (2.3.0)\n",
      "Requirement already satisfied: jax>=0.3.15 in /Users/ankitasingh/miniconda3/envs/tf/lib/python3.9/site-packages (from tensorflow) (0.4.10)\n",
      "Requirement already satisfied: six>=1.12.0 in /Users/ankitasingh/miniconda3/envs/tf/lib/python3.9/site-packages (from tensorflow) (1.16.0)\n",
      "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 in /Users/ankitasingh/miniconda3/envs/tf/lib/python3.9/site-packages (from tensorflow) (4.23.1)\n",
      "Requirement already satisfied: flatbuffers>=2.0 in /Users/ankitasingh/miniconda3/envs/tf/lib/python3.9/site-packages (from tensorflow) (23.5.9)\n",
      "Requirement already satisfied: packaging in /Users/ankitasingh/miniconda3/envs/tf/lib/python3.9/site-packages (from tensorflow) (23.1)\n",
      "Requirement already satisfied: astunparse>=1.6.0 in /Users/ankitasingh/miniconda3/envs/tf/lib/python3.9/site-packages (from tensorflow) (1.6.3)\n",
      "Requirement already satisfied: gast<=0.4.0,>=0.2.1 in /Users/ankitasingh/miniconda3/envs/tf/lib/python3.9/site-packages (from tensorflow) (0.4.0)\n",
      "Requirement already satisfied: libclang>=13.0.0 in /Users/ankitasingh/miniconda3/envs/tf/lib/python3.9/site-packages (from tensorflow) (16.0.0)\n",
      "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /Users/ankitasingh/miniconda3/envs/tf/lib/python3.9/site-packages (from tensorflow) (1.55.0)\n",
      "Requirement already satisfied: typing-extensions>=3.6.6 in /Users/ankitasingh/miniconda3/envs/tf/lib/python3.9/site-packages (from tensorflow) (4.6.0)\n",
      "Requirement already satisfied: setuptools in /Users/ankitasingh/miniconda3/envs/tf/lib/python3.9/site-packages (from tensorflow) (66.0.0)\n",
      "Requirement already satisfied: opt-einsum>=2.3.2 in /Users/ankitasingh/miniconda3/envs/tf/lib/python3.9/site-packages (from tensorflow) (3.3.0)\n",
      "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /Users/ankitasingh/miniconda3/envs/tf/lib/python3.9/site-packages (from tensorflow) (0.32.0)\n",
      "Requirement already satisfied: google-pasta>=0.1.1 in /Users/ankitasingh/miniconda3/envs/tf/lib/python3.9/site-packages (from tensorflow) (0.2.0)\n",
      "Requirement already satisfied: wrapt<1.15,>=1.11.0 in /Users/ankitasingh/miniconda3/envs/tf/lib/python3.9/site-packages (from tensorflow) (1.14.1)\n",
      "Requirement already satisfied: tensorboard<2.13,>=2.12 in /Users/ankitasingh/miniconda3/envs/tf/lib/python3.9/site-packages (from tensorflow) (2.12.3)\n",
      "Requirement already satisfied: h5py>=2.9.0 in /Users/ankitasingh/miniconda3/envs/tf/lib/python3.9/site-packages (from tensorflow) (3.8.0)\n",
      "Collecting numpy<1.24,>=1.22\n",
      "  Using cached numpy-1.23.5-cp39-cp39-macosx_10_9_x86_64.whl (18.1 MB)\n",
      "Requirement already satisfied: absl-py>=1.0.0 in /Users/ankitasingh/miniconda3/envs/tf/lib/python3.9/site-packages (from tensorflow) (1.4.0)\n",
      "Requirement already satisfied: tensorflow-estimator<2.13,>=2.12.0 in /Users/ankitasingh/miniconda3/envs/tf/lib/python3.9/site-packages (from tensorflow) (2.12.0)\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in /Users/ankitasingh/miniconda3/envs/tf/lib/python3.9/site-packages (from astunparse>=1.6.0->tensorflow) (0.35.1)\n",
      "Requirement already satisfied: scipy>=1.7 in /Users/ankitasingh/miniconda3/envs/tf/lib/python3.9/site-packages (from jax>=0.3.15->tensorflow) (1.10.1)\n",
      "Requirement already satisfied: ml-dtypes>=0.1.0 in /Users/ankitasingh/miniconda3/envs/tf/lib/python3.9/site-packages (from jax>=0.3.15->tensorflow) (0.1.0)\n",
      "Requirement already satisfied: markdown>=2.6.8 in /Users/ankitasingh/miniconda3/envs/tf/lib/python3.9/site-packages (from tensorboard<2.13,>=2.12->tensorflow) (3.4.3)\n",
      "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /Users/ankitasingh/miniconda3/envs/tf/lib/python3.9/site-packages (from tensorboard<2.13,>=2.12->tensorflow) (0.7.0)\n",
      "Requirement already satisfied: google-auth-oauthlib<1.1,>=0.5 in /Users/ankitasingh/miniconda3/envs/tf/lib/python3.9/site-packages (from tensorboard<2.13,>=2.12->tensorflow) (1.0.0)\n",
      "Requirement already satisfied: google-auth<3,>=1.6.3 in /Users/ankitasingh/miniconda3/envs/tf/lib/python3.9/site-packages (from tensorboard<2.13,>=2.12->tensorflow) (2.18.1)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in /Users/ankitasingh/miniconda3/envs/tf/lib/python3.9/site-packages (from tensorboard<2.13,>=2.12->tensorflow) (2.3.4)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in /Users/ankitasingh/miniconda3/envs/tf/lib/python3.9/site-packages (from tensorboard<2.13,>=2.12->tensorflow) (2.31.0)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in /Users/ankitasingh/miniconda3/envs/tf/lib/python3.9/site-packages (from google-auth<3,>=1.6.3->tensorboard<2.13,>=2.12->tensorflow) (0.3.0)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in /Users/ankitasingh/miniconda3/envs/tf/lib/python3.9/site-packages (from google-auth<3,>=1.6.3->tensorboard<2.13,>=2.12->tensorflow) (4.9)\n",
      "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /Users/ankitasingh/miniconda3/envs/tf/lib/python3.9/site-packages (from google-auth<3,>=1.6.3->tensorboard<2.13,>=2.12->tensorflow) (5.3.0)\n",
      "Requirement already satisfied: urllib3<2.0 in /Users/ankitasingh/miniconda3/envs/tf/lib/python3.9/site-packages (from google-auth<3,>=1.6.3->tensorboard<2.13,>=2.12->tensorflow) (1.26.15)\n",
      "Requirement already satisfied: requests-oauthlib>=0.7.0 in /Users/ankitasingh/miniconda3/envs/tf/lib/python3.9/site-packages (from google-auth-oauthlib<1.1,>=0.5->tensorboard<2.13,>=2.12->tensorflow) (1.3.1)\n",
      "Requirement already satisfied: importlib-metadata>=4.4 in /Users/ankitasingh/miniconda3/envs/tf/lib/python3.9/site-packages (from markdown>=2.6.8->tensorboard<2.13,>=2.12->tensorflow) (6.6.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Users/ankitasingh/miniconda3/envs/tf/lib/python3.9/site-packages (from requests<3,>=2.21.0->tensorboard<2.13,>=2.12->tensorflow) (3.4)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /Users/ankitasingh/miniconda3/envs/tf/lib/python3.9/site-packages (from requests<3,>=2.21.0->tensorboard<2.13,>=2.12->tensorflow) (3.1.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/ankitasingh/miniconda3/envs/tf/lib/python3.9/site-packages (from requests<3,>=2.21.0->tensorboard<2.13,>=2.12->tensorflow) (2023.5.7)\n",
      "Requirement already satisfied: MarkupSafe>=2.1.1 in /Users/ankitasingh/miniconda3/envs/tf/lib/python3.9/site-packages (from werkzeug>=1.0.1->tensorboard<2.13,>=2.12->tensorflow) (2.1.2)\n",
      "Requirement already satisfied: zipp>=0.5 in /Users/ankitasingh/miniconda3/envs/tf/lib/python3.9/site-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard<2.13,>=2.12->tensorflow) (3.15.0)\n",
      "Requirement already satisfied: pyasn1<0.6.0,>=0.4.6 in /Users/ankitasingh/miniconda3/envs/tf/lib/python3.9/site-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.13,>=2.12->tensorflow) (0.5.0)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in /Users/ankitasingh/miniconda3/envs/tf/lib/python3.9/site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<1.1,>=0.5->tensorboard<2.13,>=2.12->tensorflow) (3.2.2)\n",
      "Installing collected packages: numpy\n",
      "  Attempting uninstall: numpy\n",
      "    Found existing installation: numpy 1.24.3\n",
      "    Uninstalling numpy-1.24.3:\n",
      "      Successfully uninstalled numpy-1.24.3\n",
      "Successfully installed numpy-1.23.5\n"
     ]
    }
   ],
   "source": [
    "!pip install tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "72bf265d",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'tensorflow'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Input \u001b[0;32mIn [3]\u001b[0m, in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mos\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mshutil\u001b[39;00m\n\u001b[0;32m----> 4\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mtf\u001b[39;00m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtensorflow_hub\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mhub\u001b[39;00m\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtensorflow_text\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mtext\u001b[39;00m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'tensorflow'"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import shutil\n",
    "\n",
    "import tensorflow as tf\n",
    "import tensorflow_hub as hub\n",
    "import tensorflow_text as text\n",
    "from official.nlp import optimization \n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "tf.get_logger().setLevel('ERROR')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5c041e8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "tfhub_handle_preprocess = 'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3'\n",
    "tfhub_handle_encoder = 'https://tfhub.dev/tensorflow/small_bert/bert_en_uncased_L-2_H-512_A-8/1'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0034eed8",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "Op type not registered 'CaseFoldUTF8' in binary running on Ankitas-MacBook-Pro-3.local. Make sure the Op and Kernel are registered in the binary running in this process. Note that if you are loading a saved graph which used ops from tf.contrib, accessing (e.g.) `tf.contrib.resampler` should be done before importing the graph, as contrib ops are lazily registered when the module is first accessed.\n You may be trying to load on a different device from the computational device. Consider setting the `experimental_io_device` option in `tf.saved_model.LoadOptions` to the io_device such as '/job:localhost'.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.8/site-packages/tensorflow/python/framework/ops.py:4175\u001b[0m, in \u001b[0;36mGraph._get_op_def\u001b[0;34m(self, type)\u001b[0m\n\u001b[1;32m   4174\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 4175\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_op_def_cache\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;28;43mtype\u001b[39;49m\u001b[43m]\u001b[49m\n\u001b[1;32m   4176\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m:\n",
      "\u001b[0;31mKeyError\u001b[0m: 'CaseFoldUTF8'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mNotFoundError\u001b[0m                             Traceback (most recent call last)",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.8/site-packages/tensorflow/python/saved_model/load.py:974\u001b[0m, in \u001b[0;36mload_internal\u001b[0;34m(export_dir, tags, options, loader_cls, filters)\u001b[0m\n\u001b[1;32m    973\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 974\u001b[0m   loader \u001b[38;5;241m=\u001b[39m \u001b[43mloader_cls\u001b[49m\u001b[43m(\u001b[49m\u001b[43mobject_graph_proto\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msaved_model_proto\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mexport_dir\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    975\u001b[0m \u001b[43m                      \u001b[49m\u001b[43mckpt_options\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptions\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfilters\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    976\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m errors\u001b[38;5;241m.\u001b[39mNotFoundError \u001b[38;5;28;01mas\u001b[39;00m err:\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.8/site-packages/tensorflow/python/saved_model/load.py:148\u001b[0m, in \u001b[0;36mLoader.__init__\u001b[0;34m(self, object_graph_proto, saved_model_proto, export_dir, ckpt_options, save_options, filters)\u001b[0m\n\u001b[1;32m    146\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_export_dir \u001b[38;5;241m=\u001b[39m export_dir\n\u001b[1;32m    147\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_concrete_functions \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m--> 148\u001b[0m     \u001b[43mfunction_deserialization\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload_function_def_library\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    149\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlibrary\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmeta_graph\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgraph_def\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlibrary\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    150\u001b[0m \u001b[43m        \u001b[49m\u001b[43msaved_object_graph\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_proto\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    151\u001b[0m \u001b[43m        \u001b[49m\u001b[43mwrapper_function\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m_WrapperFunction\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[1;32m    152\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_checkpoint_options \u001b[38;5;241m=\u001b[39m ckpt_options\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.8/site-packages/tensorflow/python/saved_model/function_deserialization.py:406\u001b[0m, in \u001b[0;36mload_function_def_library\u001b[0;34m(library, saved_object_graph, load_shared_name_suffix, wrapper_function)\u001b[0m\n\u001b[1;32m    405\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m graph\u001b[38;5;241m.\u001b[39mas_default():\n\u001b[0;32m--> 406\u001b[0m   func_graph \u001b[38;5;241m=\u001b[39m \u001b[43mfunction_def_lib\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfunction_def_to_graph\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    407\u001b[0m \u001b[43m      \u001b[49m\u001b[43mcopy\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    408\u001b[0m \u001b[43m      \u001b[49m\u001b[43mstructured_input_signature\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstructured_input_signature\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    409\u001b[0m \u001b[43m      \u001b[49m\u001b[43mstructured_outputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstructured_outputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    410\u001b[0m \u001b[38;5;66;03m# Restores gradients for function-call ops (not the same as ops that use\u001b[39;00m\n\u001b[1;32m    411\u001b[0m \u001b[38;5;66;03m# custom gradients)\u001b[39;00m\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.8/site-packages/tensorflow/python/framework/function_def_to_graph.py:70\u001b[0m, in \u001b[0;36mfunction_def_to_graph\u001b[0;34m(fdef, structured_input_signature, structured_outputs, input_shapes)\u001b[0m\n\u001b[1;32m     69\u001b[0m     input_shapes \u001b[38;5;241m=\u001b[39m input_shapes_attr\u001b[38;5;241m.\u001b[39mlist\u001b[38;5;241m.\u001b[39mshape\n\u001b[0;32m---> 70\u001b[0m graph_def, nested_to_flat_tensor_name \u001b[38;5;241m=\u001b[39m \u001b[43mfunction_def_to_graph_def\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     71\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfdef\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minput_shapes\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     73\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m func_graph\u001b[38;5;241m.\u001b[39mas_default():\n\u001b[1;32m     74\u001b[0m   \u001b[38;5;66;03m# Add all function nodes to the graph.\u001b[39;00m\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.8/site-packages/tensorflow/python/framework/function_def_to_graph.py:239\u001b[0m, in \u001b[0;36mfunction_def_to_graph_def\u001b[0;34m(fdef, input_shapes)\u001b[0m\n\u001b[1;32m    238\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 239\u001b[0m   op_def \u001b[38;5;241m=\u001b[39m \u001b[43mdefault_graph\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_op_def\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnode_def\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mop\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# pylint: disable=protected-access\u001b[39;00m\n\u001b[1;32m    241\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m attr \u001b[38;5;129;01min\u001b[39;00m op_def\u001b[38;5;241m.\u001b[39mattr:\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.8/site-packages/tensorflow/python/framework/ops.py:4179\u001b[0m, in \u001b[0;36mGraph._get_op_def\u001b[0;34m(self, type)\u001b[0m\n\u001b[1;32m   4177\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m c_api_util\u001b[38;5;241m.\u001b[39mtf_buffer() \u001b[38;5;28;01mas\u001b[39;00m buf:\n\u001b[1;32m   4178\u001b[0m   \u001b[38;5;66;03m# pylint: disable=protected-access\u001b[39;00m\n\u001b[0;32m-> 4179\u001b[0m   \u001b[43mpywrap_tf_session\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mTF_GraphGetOpDef\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_c_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcompat\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mas_bytes\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mtype\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   4180\u001b[0m \u001b[43m                                     \u001b[49m\u001b[43mbuf\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   4181\u001b[0m   \u001b[38;5;66;03m# pylint: enable=protected-access\u001b[39;00m\n",
      "\u001b[0;31mNotFoundError\u001b[0m: Op type not registered 'CaseFoldUTF8' in binary running on Ankitas-MacBook-Pro-3.local. Make sure the Op and Kernel are registered in the binary running in this process. Note that if you are loading a saved graph which used ops from tf.contrib, accessing (e.g.) `tf.contrib.resampler` should be done before importing the graph, as contrib ops are lazily registered when the module is first accessed.",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Input \u001b[0;32mIn [6]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0m bert_preprocess_model \u001b[38;5;241m=\u001b[39m \u001b[43mhub\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mKerasLayer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtfhub_handle_preprocess\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      2\u001b[0m bert_model \u001b[38;5;241m=\u001b[39m hub\u001b[38;5;241m.\u001b[39mKerasLayer(tfhub_handle_encoder)\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.8/site-packages/tensorflow_hub/keras_layer.py:153\u001b[0m, in \u001b[0;36mKerasLayer.__init__\u001b[0;34m(self, handle, trainable, arguments, _sentinel, tags, signature, signature_outputs_as_dict, output_key, output_shape, load_options, **kwargs)\u001b[0m\n\u001b[1;32m    149\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_output_shape \u001b[38;5;241m=\u001b[39m data_structures\u001b[38;5;241m.\u001b[39mNoDependency(\n\u001b[1;32m    150\u001b[0m       _convert_nest_to_shapes(output_shape))\n\u001b[1;32m    152\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_load_options \u001b[38;5;241m=\u001b[39m load_options\n\u001b[0;32m--> 153\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_func \u001b[38;5;241m=\u001b[39m \u001b[43mload_module\u001b[49m\u001b[43m(\u001b[49m\u001b[43mhandle\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtags\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_load_options\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    154\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_has_training_argument \u001b[38;5;241m=\u001b[39m func_has_training_argument(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_func)\n\u001b[1;32m    155\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_is_hub_module_v1 \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mgetattr\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_func, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_is_hub_module_v1\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mFalse\u001b[39;00m)\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.8/site-packages/tensorflow_hub/keras_layer.py:449\u001b[0m, in \u001b[0;36mload_module\u001b[0;34m(handle, tags, load_options)\u001b[0m\n\u001b[1;32m    447\u001b[0m   \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mImportError\u001b[39;00m:  \u001b[38;5;66;03m# Expected before TF2.4.\u001b[39;00m\n\u001b[1;32m    448\u001b[0m     set_load_options \u001b[38;5;241m=\u001b[39m load_options\n\u001b[0;32m--> 449\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mmodule_v2\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[43mhandle\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtags\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtags\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mset_load_options\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.8/site-packages/tensorflow_hub/module_v2.py:106\u001b[0m, in \u001b[0;36mload\u001b[0;34m(handle, tags, options)\u001b[0m\n\u001b[1;32m    103\u001b[0m   obj \u001b[38;5;241m=\u001b[39m tf\u001b[38;5;241m.\u001b[39mcompat\u001b[38;5;241m.\u001b[39mv1\u001b[38;5;241m.\u001b[39msaved_model\u001b[38;5;241m.\u001b[39mload_v2(\n\u001b[1;32m    104\u001b[0m       module_path, tags\u001b[38;5;241m=\u001b[39mtags, options\u001b[38;5;241m=\u001b[39moptions)\n\u001b[1;32m    105\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 106\u001b[0m   obj \u001b[38;5;241m=\u001b[39m \u001b[43mtf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcompat\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mv1\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msaved_model\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload_v2\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodule_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtags\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtags\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    107\u001b[0m obj\u001b[38;5;241m.\u001b[39m_is_hub_module_v1 \u001b[38;5;241m=\u001b[39m is_hub_module_v1  \u001b[38;5;66;03m# pylint: disable=protected-access\u001b[39;00m\n\u001b[1;32m    108\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m obj\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.8/site-packages/tensorflow/python/saved_model/load.py:936\u001b[0m, in \u001b[0;36mload\u001b[0;34m(export_dir, tags, options)\u001b[0m\n\u001b[1;32m    845\u001b[0m \u001b[38;5;129m@tf_export\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msaved_model.load\u001b[39m\u001b[38;5;124m\"\u001b[39m, v1\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msaved_model.load_v2\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n\u001b[1;32m    846\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mload\u001b[39m(export_dir, tags\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, options\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[1;32m    847\u001b[0m   \u001b[38;5;124;03m\"\"\"Load a SavedModel from `export_dir`.\u001b[39;00m\n\u001b[1;32m    848\u001b[0m \n\u001b[1;32m    849\u001b[0m \u001b[38;5;124;03m  Signatures associated with the SavedModel are available as functions:\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    934\u001b[0m \u001b[38;5;124;03m    ValueError: If `tags` don't match a MetaGraph in the SavedModel.\u001b[39;00m\n\u001b[1;32m    935\u001b[0m \u001b[38;5;124;03m  \"\"\"\u001b[39;00m\n\u001b[0;32m--> 936\u001b[0m   result \u001b[38;5;241m=\u001b[39m \u001b[43mload_internal\u001b[49m\u001b[43m(\u001b[49m\u001b[43mexport_dir\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtags\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptions\u001b[49m\u001b[43m)\u001b[49m[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mroot\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m    937\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m result\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.8/site-packages/tensorflow/python/saved_model/load.py:977\u001b[0m, in \u001b[0;36mload_internal\u001b[0;34m(export_dir, tags, options, loader_cls, filters)\u001b[0m\n\u001b[1;32m    974\u001b[0m   loader \u001b[38;5;241m=\u001b[39m loader_cls(object_graph_proto, saved_model_proto, export_dir,\n\u001b[1;32m    975\u001b[0m                       ckpt_options, options, filters)\n\u001b[1;32m    976\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m errors\u001b[38;5;241m.\u001b[39mNotFoundError \u001b[38;5;28;01mas\u001b[39;00m err:\n\u001b[0;32m--> 977\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mFileNotFoundError\u001b[39;00m(\n\u001b[1;32m    978\u001b[0m       \u001b[38;5;28mstr\u001b[39m(err) \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m You may be trying to load on a different device \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    979\u001b[0m       \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfrom the computational device. Consider setting the \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    980\u001b[0m       \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m`experimental_io_device` option in `tf.saved_model.LoadOptions` \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    981\u001b[0m       \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mto the io_device such as \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m/job:localhost\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    982\u001b[0m root \u001b[38;5;241m=\u001b[39m loader\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;241m0\u001b[39m)\n\u001b[1;32m    983\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(loader, Loader):\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: Op type not registered 'CaseFoldUTF8' in binary running on Ankitas-MacBook-Pro-3.local. Make sure the Op and Kernel are registered in the binary running in this process. Note that if you are loading a saved graph which used ops from tf.contrib, accessing (e.g.) `tf.contrib.resampler` should be done before importing the graph, as contrib ops are lazily registered when the module is first accessed.\n You may be trying to load on a different device from the computational device. Consider setting the `experimental_io_device` option in `tf.saved_model.LoadOptions` to the io_device such as '/job:localhost'."
     ]
    }
   ],
   "source": [
    "bert_preprocess_model = hub.KerasLayer(tfhub_handle_preprocess)\n",
    "bert_model = hub.KerasLayer(tfhub_handle_encoder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ea12cdc",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
